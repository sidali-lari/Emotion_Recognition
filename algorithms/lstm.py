# -*- coding: utf-8 -*-
"""LSTM.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1aU3fcAom4N48VY1DMMw4RVdthYuMEpgb

# Import libraries
"""

import pandas as pd
import pandas as pd
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import make_pipeline
from imblearn.over_sampling import SMOTE
from sklearn.utils import class_weight
from keras.layers import LSTM, Dense
from keras.models import Sequential
from keras.optimizers import Adam
from sklearn.metrics import classification_report
from keras.utils import to_categorical
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
import numpy as np
import random

"""# Import DataSet"""

df_gsr = pd.read_csv('GSR_FeaturesExtracted.csv')
df_ecg = pd.read_csv('ECG_FeaturesExtracted.csv')
df_eye_tracking = pd.read_csv('EyeTracking_FeaturesExtracted.csv')
#df_gsr_ecg = pd.read_csv('GSR+ECG.csv')
df_all_data = pd.read_csv('all_data.csv')

"""# LSTM - GSR - 4 class"""

random.seed(42)
X = df_gsr.drop('Quad_Cat', axis=1)
y = df_gsr['Quad_Cat']
# Scaling the features
scaler = StandardScaler()
X = scaler.fit_transform(df_gsr)
X = X.reshape(-1, 1, X.shape[1])
df_labels = df_gsr['Quad_Cat']

# Converting labels to integer then to categorical
encoder = LabelEncoder()
encoder.fit(df_labels)
encoded_y = encoder.transform(df_labels)
y = to_categorical(encoded_y)

# Spliting the data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)

# Bulding the model
model = Sequential()
model.add(LSTM(50, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))
model.add(LSTM(50))
model.add(Dense(y.shape[1], activation='softmax'))

# Compile & Train
model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])
model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=32)

# Predict
y_pred = model.predict(X_test)
y_pred_classes = np.argmax(y_pred, axis=1)
y_true = np.argmax(y_test, axis=1)

# Print classification report
print(classification_report(y_true, y_pred_classes))

from keras.utils import plot_model
plot_model(model, to_file = 'model_plot.png', show_shapes = True, show_layer_names=True)

"""# LSTM GSR - Arousal"""

random.seed(42)
arousal_df = df_gsr[['Quad_Cat', 'Mean', 'SD', 'Variance', 'Minimum', 'Maximum',
   'Number of Peaks', 'Number of Valleys', 'Ratio']].copy()
arousal_mapping = {0: 'High Arousal', 1: 'Low Arousal', 2: 'Low Arousal', 3: 'High Arousal'}
arousal_df['Quad_Cat'] = arousal_df['Quad_Cat'].map(arousal_mapping)
X_arousal = arousal_df.drop('Quad_Cat', axis=1)
y_arousal = arousal_df['Quad_Cat']
scaler = StandardScaler()
X_arousal_scaled = scaler.fit_transform(X_arousal)
X_arousal_reshaped = X_arousal_scaled.reshape(-1, 1, X_arousal_scaled.shape[1])
encoder = LabelEncoder()
encoder.fit(y_arousal)
encoded_y = encoder.transform(y_arousal)
y_arousal_categorical = to_categorical(encoded_y)
X_train, X_test, y_train, y_test = train_test_split(X_arousal_reshaped, y_arousal_categorical, test_size=0.1, random_state=42)
model = Sequential()
model.add(LSTM(50, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))
model.add(LSTM(50))
model.add(Dense(y_arousal_categorical.shape[1], activation='softmax'))
model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])
model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=32)
y_pred = model.predict(X_test)
y_pred_classes = np.argmax(y_pred, axis=1)
y_true = np.argmax(y_test, axis=1)
print(classification_report(y_true, y_pred_classes))

"""# LSTM GSR - Valence"""

random.seed(42)
valence_df = df_gsr[['Quad_Cat', 'Mean', 'SD', 'Variance', 'Minimum', 'Maximum',
       'Number of Peaks', 'Number of Valleys', 'Ratio']].copy()
valence_mapping = {0: 'High Valence', 1: 'High Valence', 2: 'Low Valence', 3: 'Low Valence'}
valence_df['Quad_Cat'] = valence_df['Quad_Cat'].map(valence_mapping)

X_valence = valence_df.drop('Quad_Cat', axis=1)
y_valence = valence_df['Quad_Cat']

scaler = StandardScaler()
X_valence_scaled = scaler.fit_transform(X_valence)

X_valence_reshaped = X_valence_scaled.reshape(-1, 1, X_valence_scaled.shape[1])

encoder = LabelEncoder()
encoder.fit(y_valence)
encoded_y = encoder.transform(y_valence)
y_valence_categorical = to_categorical(encoded_y)

X_train, X_test, y_train, y_test = train_test_split(X_valence_reshaped, y_valence_categorical, test_size=0.1, random_state=42)

model = Sequential()
model.add(LSTM(50, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))
model.add(LSTM(50))
model.add(Dense(y_valence_categorical.shape[1], activation='softmax'))

model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])

model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=32)

y_pred = model.predict(X_test)
y_pred_classes = np.argmax(y_pred, axis=1)
y_true = np.argmax(y_test, axis=1)

print(classification_report(y_true, y_pred_classes))

"""# LSTM ECG - 4 Class"""

random.seed(42)
X = df_ecg.drop('Quad_Cat', axis=1)
y = df_ecg['Quad_Cat']
# Scaling the features
scaler = StandardScaler()
X = scaler.fit_transform(df_ecg)
X = X.reshape(-1, 1, X.shape[1])
df_labels = df_ecg['Quad_Cat']

# Converting labels to integer then to categorical
encoder = LabelEncoder()
encoder.fit(df_labels)
encoded_y = encoder.transform(df_labels)
y = to_categorical(encoded_y)

# Spliting the data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)

# Bulding the model
model = Sequential()
model.add(LSTM(50, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))
model.add(LSTM(50))
model.add(Dense(y.shape[1], activation='softmax'))

# Compile & Train
model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])
model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=32)

# Predict
y_pred = model.predict(X_test)
y_pred_classes = np.argmax(y_pred, axis=1)
y_true = np.argmax(y_test, axis=1)

# Print classification report
print(classification_report(y_true, y_pred_classes))

"""# LSTM ECG - Arousal"""

random.seed(42)
arousal_df = df_ecg[['Quad_Cat', 'Mean', 'Min', 'Max', 'MeanRR', 'MedianRR', 'MinRR',
       'MaxRR', 'LF', 'HF', 'VLF', 'Ibi', 'Bpm', 'Sdnn', 'Sdsd', 'Rmssd',
       'Pnn50', 'pnn20', 'Pnn50pnn20']].copy()
arousal_mapping = {0: 'High Arousal', 1: 'Low Arousal', 2: 'Low Arousal', 3: 'High Arousal'}
arousal_df['Quad_Cat'] = arousal_df['Quad_Cat'].map(arousal_mapping)
X_arousal = arousal_df.drop('Quad_Cat', axis=1)
y_arousal = arousal_df['Quad_Cat']
scaler = StandardScaler()
X_arousal_scaled = scaler.fit_transform(X_arousal)
X_arousal_reshaped = X_arousal_scaled.reshape(-1, 1, X_arousal_scaled.shape[1])
encoder = LabelEncoder()
encoder.fit(y_arousal)
encoded_y = encoder.transform(y_arousal)
y_arousal_categorical = to_categorical(encoded_y)
X_train, X_test, y_train, y_test = train_test_split(X_arousal_reshaped, y_arousal_categorical, test_size=0.1, random_state=42)
model = Sequential()
model.add(LSTM(50, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))
model.add(LSTM(50))
model.add(Dense(y_arousal_categorical.shape[1], activation='softmax'))
model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])
model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=32)
y_pred = model.predict(X_test)
y_pred_classes = np.argmax(y_pred, axis=1)
y_true = np.argmax(y_test, axis=1)
print(classification_report(y_true, y_pred_classes))

"""# LSTM ECG - Valence"""

random.seed(42)
valence_df = df_ecg[['Quad_Cat', 'Mean', 'Min', 'Max', 'MeanRR', 'MedianRR', 'MinRR',
       'MaxRR', 'LF', 'HF', 'VLF', 'Ibi', 'Bpm', 'Sdnn', 'Sdsd', 'Rmssd',
       'Pnn50', 'pnn20', 'Pnn50pnn20']].copy()
valence_mapping = {0: 'High Valence', 1: 'High Valence', 2: 'Low Valence', 3: 'Low Valence'}
valence_df['Quad_Cat'] = valence_df['Quad_Cat'].map(valence_mapping)

X_valence = valence_df.drop('Quad_Cat', axis=1)
y_valence = valence_df['Quad_Cat']

scaler = StandardScaler()
X_valence_scaled = scaler.fit_transform(X_valence)

X_valence_reshaped = X_valence_scaled.reshape(-1, 1, X_valence_scaled.shape[1])

encoder = LabelEncoder()
encoder.fit(y_valence)
encoded_y = encoder.transform(y_valence)
y_valence_categorical = to_categorical(encoded_y)

X_train, X_test, y_train, y_test = train_test_split(X_valence_reshaped, y_valence_categorical, test_size=0.1, random_state=42)

model = Sequential()
model.add(LSTM(50, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))
model.add(LSTM(50))
model.add(Dense(y_valence_categorical.shape[1], activation='softmax'))

model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])

model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=32)

y_pred = model.predict(X_test)
y_pred_classes = np.argmax(y_pred, axis=1)
y_true = np.argmax(y_test, axis=1)

print(classification_report(y_true, y_pred_classes))

"""# Eye Tracking 4 - Class"""

### -- Eye Trakcing
df_eye_tracking.dropna(inplace=True)
# Drop columns with NaN values
df_eye_tracking.dropna(axis=1, inplace=True)

random.seed(42)
X = df_eye_tracking.drop('Quad_Cat', axis=1)
y = df_eye_tracking['Quad_Cat']
# Scaling the features
scaler = StandardScaler()
X = scaler.fit_transform(df_eye_tracking)
X = X.reshape(-1, 1, X.shape[1])
df_labels = df_eye_tracking['Quad_Cat']

# Converting labels to integer then to categorical
encoder = LabelEncoder()
encoder.fit(df_labels)
encoded_y = encoder.transform(df_labels)
y = to_categorical(encoded_y)

# Spliting the data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)

# Bulding the model
model = Sequential()
model.add(LSTM(50, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))
model.add(LSTM(50))
model.add(Dense(y.shape[1], activation='softmax'))

# Compile & Train
model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])
model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=32)

# Predict
y_pred = model.predict(X_test)
y_pred_classes = np.argmax(y_pred, axis=1)
y_true = np.argmax(y_test, axis=1)

# Print classification report
print(classification_report(y_true, y_pred_classes))

"""# LSTM Eye Tracking Arousal"""

random.seed(42)
arousal_df = df_eye_tracking[['Quad_Cat', 'Num_of_Fixations', 'Mean_Fixation_Duration',
       'SD_Fixation_Duration', 'Skew_Fixation_Duration',
       'Max_Fixation_Duration', 'First_Fixation_Duration', 'Num_of_Saccade',
       'Mean_Saccade_Duration', 'SD_Saccade_Duration', 'Skew_Saccade_Duration',
       'Max_Saccade_Duration', 'Mean_Saccade_Amplitude',
       'SD_Saccade_Amplitude', 'Skew_Saccade_Amplitude',
       'Max_Saccade_Amplitude', 'Mean_Saccade_Direction',
       'SD_Saccade_Direction', 'Skew_Saccade_Direction',
       'Max_Saccade_Direction', 'Mean_Saccade_Length', 'SD_Saccade_Length',
       'Skew_Saccade_Length', 'Max_Saccade_Length', 'Num_of_Blink',
       'Mean_Blink_Duration', 'SD_Blink_Duration', 'Skew_Blink_Duration',
       'Max_Blink_Duration', 'Num_of_Microsac', 'Mean_Microsac_Peak_Vel',
       'SD_Microsac_Peak_Vel', 'Skew_Microsac_Peak_Vel',
       'Max_Microsac_Peak_Vel', 'Mean_Microsac_Ampl', 'SD_Microsac_Ampl',
       'Skew_Microsac_Ampl', 'Max_Microsac_Ampl', 'Mean_Microsac_Dir',
       'SD_Microsac_Dir', 'Skew_Microsac_Dir', 'Max_Microsac_Dir',
       'Mean_Microsac_H_Amp', 'SD_Microsac_H_Amp', 'Skew_Microsac_H_Amp',
       'Max_Microsac_H_Amp', 'Mean_Microsac_V_Amp', 'SD_Microsac_V_Amp',
       'Skew_Microsac_V_Amp', 'Max_Microsac_V_Amp']].copy()
arousal_mapping = {0: 'High Arousal', 1: 'Low Arousal', 2: 'Low Arousal', 3: 'High Arousal'}
arousal_df['Quad_Cat'] = arousal_df['Quad_Cat'].map(arousal_mapping)
X_arousal = arousal_df.drop('Quad_Cat', axis=1)
y_arousal = arousal_df['Quad_Cat']
scaler = StandardScaler()
X_arousal_scaled = scaler.fit_transform(X_arousal)
X_arousal_reshaped = X_arousal_scaled.reshape(-1, 1, X_arousal_scaled.shape[1])
encoder = LabelEncoder()
encoder.fit(y_arousal)
encoded_y = encoder.transform(y_arousal)
y_arousal_categorical = to_categorical(encoded_y)
X_train, X_test, y_train, y_test = train_test_split(X_arousal_reshaped, y_arousal_categorical, test_size=0.1, random_state=42)
model = Sequential()
model.add(LSTM(50, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))
model.add(LSTM(50))
model.add(Dense(y_arousal_categorical.shape[1], activation='softmax'))
model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])
model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=32)
y_pred = model.predict(X_test)
y_pred_classes = np.argmax(y_pred, axis=1)
y_true = np.argmax(y_test, axis=1)
print(classification_report(y_true, y_pred_classes))

"""# LSTM Eye Tracking Valence"""

random.seed(42)
valence_df = df_eye_tracking[['Quad_Cat', 'Num_of_Fixations', 'Mean_Fixation_Duration',
       'SD_Fixation_Duration', 'Skew_Fixation_Duration',
       'Max_Fixation_Duration', 'First_Fixation_Duration', 'Num_of_Saccade',
       'Mean_Saccade_Duration', 'SD_Saccade_Duration', 'Skew_Saccade_Duration',
       'Max_Saccade_Duration', 'Mean_Saccade_Amplitude',
       'SD_Saccade_Amplitude', 'Skew_Saccade_Amplitude',
       'Max_Saccade_Amplitude', 'Mean_Saccade_Direction',
       'SD_Saccade_Direction', 'Skew_Saccade_Direction',
       'Max_Saccade_Direction', 'Mean_Saccade_Length', 'SD_Saccade_Length',
       'Skew_Saccade_Length', 'Max_Saccade_Length', 'Num_of_Blink',
       'Mean_Blink_Duration', 'SD_Blink_Duration', 'Skew_Blink_Duration',
       'Max_Blink_Duration', 'Num_of_Microsac', 'Mean_Microsac_Peak_Vel',
       'SD_Microsac_Peak_Vel', 'Skew_Microsac_Peak_Vel',
       'Max_Microsac_Peak_Vel', 'Mean_Microsac_Ampl', 'SD_Microsac_Ampl',
       'Skew_Microsac_Ampl', 'Max_Microsac_Ampl', 'Mean_Microsac_Dir',
       'SD_Microsac_Dir', 'Skew_Microsac_Dir', 'Max_Microsac_Dir',
       'Mean_Microsac_H_Amp', 'SD_Microsac_H_Amp', 'Skew_Microsac_H_Amp',
       'Max_Microsac_H_Amp', 'Mean_Microsac_V_Amp', 'SD_Microsac_V_Amp',
       'Skew_Microsac_V_Amp', 'Max_Microsac_V_Amp']].copy()
valence_mapping = {0: 'High Valence', 1: 'High Valence', 2: 'Low Valence', 3: 'Low Valence'}
valence_df['Quad_Cat'] = valence_df['Quad_Cat'].map(valence_mapping)

X_valence = valence_df.drop('Quad_Cat', axis=1)
y_valence = valence_df['Quad_Cat']

scaler = StandardScaler()
X_valence_scaled = scaler.fit_transform(X_valence)

X_valence_reshaped = X_valence_scaled.reshape(-1, 1, X_valence_scaled.shape[1])

encoder = LabelEncoder()
encoder.fit(y_valence)
encoded_y = encoder.transform(y_valence)
y_valence_categorical = to_categorical(encoded_y)

X_train, X_test, y_train, y_test = train_test_split(X_valence_reshaped, y_valence_categorical, test_size=0.1, random_state=42)

model = Sequential()
model.add(LSTM(50, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))
model.add(LSTM(50))
model.add(Dense(y_valence_categorical.shape[1], activation='softmax'))

model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])

model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=32)

y_pred = model.predict(X_test)
y_pred_classes = np.argmax(y_pred, axis=1)
y_true = np.argmax(y_test, axis=1)

print(classification_report(y_true, y_pred_classes))

### -- All Data
df_all_data.dropna(inplace=True)
# Drop columns with NaN values
df_all_data.dropna(axis=1, inplace=True)

"""# LSTM - All Data -4 class"""

random.seed(42)
X = df_all_data.drop('Quad_Cat', axis=1)
y = df_all_data['Quad_Cat']
# Scaling the features
scaler = StandardScaler()
X = scaler.fit_transform(df_all_data)
X = X.reshape(-1, 1, X.shape[1])
df_labels = df_all_data['Quad_Cat']

# Converting labels to integer then to categorical
encoder = LabelEncoder()
encoder.fit(df_labels)
encoded_y = encoder.transform(df_labels)
y = to_categorical(encoded_y)

# Spliting the data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)

# Bulding the model
model = Sequential()
model.add(LSTM(50, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))
model.add(LSTM(50))
model.add(Dense(y.shape[1], activation='softmax'))

# Compile & Train
model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])
model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=32)

# Predict
y_pred = model.predict(X_test)
y_pred_classes = np.argmax(y_pred, axis=1)
y_true = np.argmax(y_test, axis=1)

# Print classification report
print(classification_report(y_true, y_pred_classes))

"""# LSTM - All Data - Arousal"""

random.seed(42)
arousal_df = df_all_data[['Quad_Cat', 'Num_of_Fixations', 'Mean_Fixation_Duration',
       'SD_Fixation_Duration', 'Skew_Fixation_Duration',
       'Max_Fixation_Duration', 'First_Fixation_Duration', 'Num_of_Saccade',
       'Mean_Saccade_Duration', 'SD_Saccade_Duration', 'Skew_Saccade_Duration',
       'Max_Saccade_Duration', 'Mean_Saccade_Amplitude',
       'SD_Saccade_Amplitude', 'Skew_Saccade_Amplitude',
       'Max_Saccade_Amplitude', 'Mean_Saccade_Direction',
       'SD_Saccade_Direction', 'Skew_Saccade_Direction',
       'Max_Saccade_Direction', 'Mean_Saccade_Length', 'SD_Saccade_Length',
       'Skew_Saccade_Length', 'Max_Saccade_Length', 'Num_of_Blink',
       'Mean_Blink_Duration', 'SD_Blink_Duration', 'Skew_Blink_Duration',
       'Max_Blink_Duration', 'Num_of_Microsac', 'Mean_Microsac_Peak_Vel',
       'SD_Microsac_Peak_Vel', 'Skew_Microsac_Peak_Vel',
       'Max_Microsac_Peak_Vel', 'Mean_Microsac_Ampl', 'SD_Microsac_Ampl',
       'Skew_Microsac_Ampl', 'Max_Microsac_Ampl', 'Mean_Microsac_Dir',
       'SD_Microsac_Dir', 'Skew_Microsac_Dir', 'Max_Microsac_Dir',
       'Mean_Microsac_H_Amp', 'SD_Microsac_H_Amp', 'Skew_Microsac_H_Amp',
       'Max_Microsac_H_Amp', 'Mean_Microsac_V_Amp', 'SD_Microsac_V_Amp',
       'Skew_Microsac_V_Amp', 'Max_Microsac_V_Amp', 'Mean', 'SD', 'Variance',
       'Minimum', 'Maximum', 'Number of Peaks', 'Number of Valleys', 'Ratio',
       'Mean.1', 'Min', 'Max', 'MeanRR', 'MedianRR', 'MinRR', 'MaxRR', 'LF',
       'HF', 'VLF', 'Ibi', 'Bpm', 'Sdnn', 'Sdsd', 'Rmssd', 'Pnn50', 'pnn20',
       'Pnn50pnn20']].copy()
arousal_mapping = {0: 'High Arousal', 1: 'Low Arousal', 2: 'Low Arousal', 3: 'High Arousal'}
arousal_df['Quad_Cat'] = arousal_df['Quad_Cat'].map(arousal_mapping)
X_arousal = arousal_df.drop('Quad_Cat', axis=1)
y_arousal = arousal_df['Quad_Cat']
scaler = StandardScaler()
X_arousal_scaled = scaler.fit_transform(X_arousal)
X_arousal_reshaped = X_arousal_scaled.reshape(-1, 1, X_arousal_scaled.shape[1])
encoder = LabelEncoder()
encoder.fit(y_arousal)
encoded_y = encoder.transform(y_arousal)
y_arousal_categorical = to_categorical(encoded_y)
X_train, X_test, y_train, y_test = train_test_split(X_arousal_reshaped, y_arousal_categorical, test_size=0.1, random_state=42)
model = Sequential()
model.add(LSTM(50, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))
model.add(LSTM(50))
model.add(Dense(y_arousal_categorical.shape[1], activation='softmax'))
model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])
model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=32)
y_pred = model.predict(X_test)
y_pred_classes = np.argmax(y_pred, axis=1)
y_true = np.argmax(y_test, axis=1)
print(classification_report(y_true, y_pred_classes))

from keras.utils import plot_model
plot_model(model, to_file = 'model_plot.png', show_shapes = True, show_layer_names=True)

"""## LSTM All Data Valence"""

random.seed(42)
valence_df = df_all_data[['Quad_Cat', 'Num_of_Fixations', 'Mean_Fixation_Duration',
       'SD_Fixation_Duration', 'Skew_Fixation_Duration',
       'Max_Fixation_Duration', 'First_Fixation_Duration', 'Num_of_Saccade',
       'Mean_Saccade_Duration', 'SD_Saccade_Duration', 'Skew_Saccade_Duration',
       'Max_Saccade_Duration', 'Mean_Saccade_Amplitude',
       'SD_Saccade_Amplitude', 'Skew_Saccade_Amplitude',
       'Max_Saccade_Amplitude', 'Mean_Saccade_Direction',
       'SD_Saccade_Direction', 'Skew_Saccade_Direction',
       'Max_Saccade_Direction', 'Mean_Saccade_Length', 'SD_Saccade_Length',
       'Skew_Saccade_Length', 'Max_Saccade_Length', 'Num_of_Blink',
       'Mean_Blink_Duration', 'SD_Blink_Duration', 'Skew_Blink_Duration',
       'Max_Blink_Duration', 'Num_of_Microsac', 'Mean_Microsac_Peak_Vel',
       'SD_Microsac_Peak_Vel', 'Skew_Microsac_Peak_Vel',
       'Max_Microsac_Peak_Vel', 'Mean_Microsac_Ampl', 'SD_Microsac_Ampl',
       'Skew_Microsac_Ampl', 'Max_Microsac_Ampl', 'Mean_Microsac_Dir',
       'SD_Microsac_Dir', 'Skew_Microsac_Dir', 'Max_Microsac_Dir',
       'Mean_Microsac_H_Amp', 'SD_Microsac_H_Amp', 'Skew_Microsac_H_Amp',
       'Max_Microsac_H_Amp', 'Mean_Microsac_V_Amp', 'SD_Microsac_V_Amp',
       'Skew_Microsac_V_Amp', 'Max_Microsac_V_Amp', 'Mean', 'SD', 'Variance',
       'Minimum', 'Maximum', 'Number of Peaks', 'Number of Valleys', 'Ratio',
       'Mean.1', 'Min', 'Max', 'MeanRR', 'MedianRR', 'MinRR', 'MaxRR', 'LF',
       'HF', 'VLF', 'Ibi', 'Bpm', 'Sdnn', 'Sdsd', 'Rmssd', 'Pnn50', 'pnn20',
       'Pnn50pnn20']].copy()
valence_mapping = {0: 'High Valence', 1: 'High Valence', 2: 'Low Valence', 3: 'Low Valence'}
valence_df['Quad_Cat'] = valence_df['Quad_Cat'].map(valence_mapping)

X_valence = valence_df.drop('Quad_Cat', axis=1)
y_valence = valence_df['Quad_Cat']

scaler = StandardScaler()
X_valence_scaled = scaler.fit_transform(X_valence)

X_valence_reshaped = X_valence_scaled.reshape(-1, 1, X_valence_scaled.shape[1])

encoder = LabelEncoder()
encoder.fit(y_valence)
encoded_y = encoder.transform(y_valence)
y_valence_categorical = to_categorical(encoded_y)

X_train, X_test, y_train, y_test = train_test_split(X_valence_reshaped, y_valence_categorical, test_size=0.1, random_state=42)

model = Sequential()
model.add(LSTM(50, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))
model.add(LSTM(50))
model.add(Dense(y_valence_categorical.shape[1], activation='softmax'))

model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])

model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=32)

y_pred = model.predict(X_test)
y_pred_classes = np.argmax(y_pred, axis=1)
y_true = np.argmax(y_test, axis=1)

print(classification_report(y_true, y_pred_classes))

from keras.utils import plot_model
plot_model(model, to_file = 'model_plot.png', show_shapes = True, show_layer_names=True)

"""# lstm test on signal segment"""

df_all_data.columns

import pickle

with open('101_ECG_GSR_PreProcessed.dat', 'rb') as file:
    data = pickle.load(file)

# If the loaded data is a pandas DataFrame, print the header
if isinstance(data, pd.DataFrame):
    print(data.head())
else:
    print("Loaded data is not a DataFrame. It's of type:", type(data))

# Display the keys of the dictionary
print(data.keys())

# Check the type of the content under each key
print("Type of 'Labels':", type(data['Labels']))
print("Type of 'Data':", type(data['Data']))

# Display first few items of 'Labels' and 'Data'
print("\n'Labels' preview:")
print(data['Labels'][:10])  # display the first 10 items if it's a list or similar structure

print("\n'Data' preview:")
if isinstance(data['Data'], list) or isinstance(data['Data'], np.ndarray):
    print(data['Data'][:10])  # display the first 10 rows if it's a list or array
else:
    print(data['Data'])

window_size = 1000

# Process data for each participant into windows and return the corresponding label
def process_participant_data(data, label):
    num_windows = len(data) // window_size
    data_windows = [data[i*window_size: (i+1)*window_size] for i in range(num_windows)]
    return data_windows, [label for _ in range(num_windows)]

# Store accuracies for each iteration
accuracies = []

# LOOCV
for i in range(len(data_list)):

    # Splitting data
    X_train_data = [process_participant_data(data_list[j], labels_list[j])[0] for j in range(len(data_list)) if j != i]
    X_train_labels = [process_participant_data(data_list[j], labels_list[j])[1] for j in range(len(data_list)) if j != i]

    X_test_windows, y_test = process_participant_data(data_list[i], labels_list[i])

    # Flatten the lists for training
    X_train = [item for sublist in X_train_data for item in sublist]
    y_train = [item for sublist in X_train_labels for item in sublist]

    # Convert labels to one-hot encoding
    num_classes = len(np.unique(np.hstack(labels_list)))  # Getting total unique classes across all participants
    y_train = to_categorical(y_train, num_classes=num_classes)
    y_test = to_categorical(y_test, num_classes=num_classes)

    # Building the model (redefine and recompile in each loop)
    model = Sequential()
    model.add(LSTM(50, return_sequences=True, input_shape=(window_size, 2)))
    model.add(LSTM(50))
    model.add(Dense(num_classes, activation='softmax'))

    # Compile
    model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])

    # Train on the combined training data
    model.fit(np.array(X_train), y_train, epochs=10, batch_size=32, verbose=0)

    # Evaluate
    results = model.evaluate(np.array(X_test_windows), y_test, verbose=0)
    accuracies.append(results[1])  # results[1] corresponds to accuracy

# Average accuracy
avg_accuracy = np.mean(accuracies)
print(f"Average accuracy across all sessions using LOOCV: {avg_accuracy:.2f}")

import random
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.metrics import classification_report
from keras.utils import to_categorical
from keras.models import Sequential
from keras.layers import LSTM, Dense
from keras.optimizers import Adam
import numpy as np

random.seed(42)


X = df_all_data.drop('Quad_Cat', axis=1)
y = df_all_data['Quad_Cat']

# Scaling the features
scaler = StandardScaler()
X = scaler.fit_transform(X)
X = X.reshape(-1, 1, X.shape[1])

# Converting labels to integer then to categorical
encoder = LabelEncoder()
encoder.fit(y)
encoded_y = encoder.transform(y)
y = to_categorical(encoded_y)

# Prepare for LOOCV
n_samples = X.shape[0]
accuracies = []

# LOOCV loop
for i in range(n_samples):
    X_train = np.vstack([X[j] for j in range(n_samples) if j != i])
    X_train = X_train.reshape(-1, 1, X_train.shape[1])
    X_test = X[i].reshape(1, X.shape[1], X.shape[2])

    y_train = np.vstack([y[j] for j in range(n_samples) if j != i])
    y_test_single = y[i].reshape(1, -1)

    # Building the model for each iteration
    model = Sequential()
    model.add(LSTM(50, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))
    model.add(LSTM(50))
    model.add(Dense(y.shape[1], activation='softmax'))

    # Compile & Train
    model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])
    model.fit(X_train, y_train, epochs=10, batch_size=32, verbose=0)

    # Evaluate
    _, accuracy = model.evaluate(X_test, y_test_single, verbose=0)
    accuracies.append(accuracy)

# Average accuracy using LOOCV
avg_accuracy = np.mean(accuracies)
print(f"Average accuracy using LOOCV: {avg_accuracy:.2f}")